






//how these are settling down is: they are generalized, but assume hide 0 and row_tick ascending false
//which is fine, and means that maybe really all your tables should have the same starting three columns
//so that you can use all of these functions on any table










/*
our tables do everthing with just a small handful of postgres types,
and our conventions for column titles identify what kind of data columns have:

example2_table            table names end _table, lowercase and numerals ok

row_tag         CHAR(21)  a globally unique tag to identify this row
row_tick        BIGNUM    set when we added the row
hide            BIGNUM    0 to start, nonzero to ignore this row in regular use
                          ^ most tables start with these three columns

password_hash   CHAR(52)  52 characters of a sha256 hash value encoded to base32
user_name_text  TEXT      text which can be blank or long

_tag, _hash, and _text are strings; everything else must be an integer
a column which can be a tag or blank is _text
as is a column which can be text or numerals, like settings_table

PRIMARY KEY is frequently row_tag, which is guaranteed to have unique tags,
even though we never query on it
every column is NOT NULL to make things simpler, generally and for .upsert()
*/

/*
to this add:
using indices, and multicolumn indices, to match common queries and makek them fast
not using foreign keys, which establish constraints between tables, and don't help performance
*/



here are the things we're accpeting:
a call to supabase takes ~100ms, some queries may have a handful of them, and we accept this can make some things the user clicks on take nearly a second to complete, a noticable delay



here are the assumptions we're making
the supabase api and workers' connections to supabase will be reliable, and the supabase api is error-free. we assume that if a call succeeds, it did what it said it would, without checking
if neighboring lines in a worker make two edits to the database, there won't be a change to the database between them
if information in the database enters an unexpected, should-be-impossible state, code is conservative enough that this won't break the app, and later changes could heal the data

essentially, i've found it's not possible to code with the database to the same level of perfection as dealing with other parts of the system
to be able to move forward, a level of trust


















/*
-- records of browsers signing in with password and signing out
CREATE TABLE access_table (
	row_tag      CHAR(21)  PRIMARY KEY  NOT NULL, -- row tag
	row_tick     BIGINT                 NOT NULL, -- when inserted
	browser_tag  CHAR(21)               NOT NULL, -- browser tag
	signed_in    BIGINT                 NOT NULL  -- 0 signed out or 1 signed in
);
-- composite index to make a filtering by browser tag and sorting by tick fast
CREATE INDEX access_index_on_browser_tick ON access_table (browser_tag, row_tick);
*/







/*
facts about postgres and choices about how we're using it:
we're using BIGINT for every integer, for simplicity, even if we only plan on storing 0 or 1
indices make queries much faster, and compound indices that match queries are a good idea
*/




we're intentionally avoiding date, duration, and uuid types
ARRAY and JSON are common; maybe you'll use those, or maybe you'll instead accomplish array-like data with simple tables with multiple rows

-also "While PostgreSQL’s query planner is quite sophisticated and can optimize queries using existing indexes, it won’t create new indexes on its own based on query usage."

other supabase things we're not using:
auto incrementing row number, BIGSERIAL
Type: "timestamptz" (timestamp with time zone)
supabase's clock, we always use now from the worker



in excel and on a piece of paper, the rows have an order, but this isn't the case in postgres
^put in section about what you've learned about databases in general
the columns do have an order, but since column titles must be unique, we can ignore it
and exchanging objects like {title1: 101, title2: 202} back and forth with the supabase api, order doesn't matter



/*
make sure postgresql has the default utf-8 character encoding with a sql statement like this:

SELECT pg_encoding_to_char(encoding) AS encoding
FROM pg_database
WHERE datname = current_database()

ran this in supabase's sql editor, and the result is "UTF8"
*/


supabase is full of darkpatterns to turn on row level security
because that's how they get you
turning off rls is fine, and common when server code has exclusive access to the database















/*
long chat about transactions that ended up with this

const sql = `
	BEGIN;
	INSERT INTO first_table (column) VALUES (quote_literal(${val1}));
	INSERT INTO second_table (column) VALUES (quote_literal(${val2}));
	COMMIT;
`
const { data, error } = await supabase.rpc('execute_sql', { sql })

imagine the database only makes sense when both, or neither of these rows are added
if one row is added, and the other one not there, the database isn't in a consistent state

also, imagine the first row inserts fine, but then
a valid error correctly prevents the second row from being inserted
there could be a uniqueness conflict on the second row, for instance

using the supabase api, each insert is a separate statement
js code will have to notice the error on the second insert
and then go back and try to remove the first

but this problem was solved in databases decades ago!
with somethign called the transaction
the begin and commit lines above group the two inserts into a single transaction
and, sure enough, if there's a problem anywhere in there, none of it sticks
and all of this is automatic

so you want to be able to use transactions
the problem is, the supabase api doesn't include them
there isn't a way to do two inserts in a single call to the supabase api, either
even with all the method chaining

so the plan is to
use the supabase api for reads
and individual writes
but when you need to insert multiple rows all at once
to drop down to raw sql and execute a block like above

but now you need to worry about the infamous sql injection attack
but maybe it's not too hard
you think essentially you just have to validate the inserts really well
and your own functions are doing this

but additionally, get protection from using knex, continued below
(that didn't work because they all assume api or node, rerouting)

also, batch raw inserts like this also will likely be faster,
as each trip to supabase is taking ~150ms
*/






/*
here's a crazy idea
your database design means that you're, at the start, going to have to get all the rows for a browser tag from maybe a half dozen different tables
then, with all those rows in the worker, you'll synthesize and decide what to do next
rather than most databases, which have requirements and a single users table, for instance

ok, so let's say that even the most trivial supabase call takes 100ms
so if you do 10 of them, that's a full second!
which is not acceptable, of course

but then you just realized, do multiple async calls in parallel in this case
yeah, how does that work in this fully finished time of async await
*/



/*
some of these ideas may be known inventions, others discredited antipatterns

every row has a tick and a tag
code never deletes a row, rather, it adds a new one later which invalidates it
or marks a cell on the row as deleted--the column name for this is standard

instead of having a table for phone numbers and a table for email addresses,
and then doing long joins from users to each,
what if we had two columns in an existing table
the first tells the type of the contents of the second, like "Email." or "Phone."
and then the second has text with the value in the correct form for that type

so then if you just want all the email address in the database
instead of looking at one entire special email table
you filter the unified omnitable by "Email."

this is starting to be a little more like a document database
but could be simple enough, and will hugely reduce the number of tables that are in there
when you add a new data type, you don't have to create a new table for it
*/


hide, 0 by default, then nonzero to hide the row, perhaps because it's made not relevant by later rows, like the user deleted it, or edited it, or it's no longer necessary to come to the same conclusion
hidden rows should never never be sent to the client, for any reason--it's ok for the server to look at them and make decisions based upon them, though
but even that should be rare--when performing an audit for a staff member, or something related to keeping the system secure as it runs



imagining how this might grow
_json, and postgres has a type for this, and if you use it a lot you sorta go into document database land, you've heard. not sure if you want to go there, but there might be a way to go there


another thing we're not doing
labeling any columns UNIQUE in the schema
tags are globally unique
and row_tag column is unique
but other columns that have tags absolutely have duplicates! multiple rows need to record facts about the same tag, like browser tag or user tag!
unique makes postgres autoatically make an index
but we're adding compound indices designed to match common queries by design
so we don't need more individual indices


yes make indices
no don't use foreign keys, they don't help with query speed

row_tag
row_tick
hide         -- initialize to zero to not hide, nonzero numbers indicate why its hidden











^from early notes, for net23.txt





supabase
[]backup and download
[]restore into local postgres
[]restore into supabase
[]setup automatic backups every 6 hours
[]that go to an amazon bucket











hit_table


/*
where the info comes from

//worker's clock
		row_tick: t,
		quarter_day: d,//cells that describe the first hit like this in this quarter day time period

//cloudflare, trusted
		ip_text: ip,
		city_text: city,

//browser, what it says it is
		browser_tag: browserTag,
		agent_text: agent,
		graphics_text: graphics

//determined from several sources
		user_tag_text: userTag,




parse these out in doorWorkerOpen, probably
workerEvent.req.headers.get('CF-Connecting-IP')
const userIp = request.headers.get("cf-connecting-ip");
ask: what kind of object is headers? what is the .get method? should i use upper or lower case here?
Because CF-Connecting-IP is added by Cloudflare’s edge, it is considered trusted. It tells you the actual IP (IPv4 or IPv6) Cloudflare sees from the client, regardless of any untrusted X-Forwarded-For or other headers the browser might send.


const cf = workerEvent.req.cf;
const city = cf?.city;         // e.g. "New York"
const region = cf?.region;     // e.g. "NY"
const country = cf?.country;   // e.g. "US"
const continent = cf?.continent; // e.g. "NA"

make sure geolocation is enabled


const cfInfo = request.cf; 
cfInfo might look like:
{
  asOrganization: "AS12345 Some ISP",
  city: "Los Angeles",
  region: "CA",
  country: "US",
  continent: "NA",
  postalCode: "90001",
  latitude: "34.0522",
  longitude: "-118.2437",
  timezone: "America/Los_Angeles",
  // ... and so on
}

request.headers.get("user-agent")


also you should only register hits onCloud()


json stringify cfInfo to see what they look like in supabase
and similarly, this is a good way to use

now code some pinia
pinia 1[]the local counter that stays when you go back to the route it's on, all local
pinia 3[]graphics info, setting once at the start


maybe actually store it parsed, not raw
because you don't want to reparse it differently later
raw is big, and not private


don't do the nvidia stuff because it isn't already on the worker
save the whole cfInfo stringified









*/










































demo
so far in the database

i've been coding for years, but am totally new to databases!
ive never written a schema before

no jwt - a format for a format, and expiration
no orm - instead just functions that look at grids of text and numbers

example_table and a demonstration of types
column title defines type for sanity checking

strategy
keep things simple and verbose in the database
keep things really simple in the browser
handfuls of quick queries in the worker bring it together

tables are ledgers; we append to them
instead of deleting a row, mark it as hidden




























don't build wide at this level at thi stime
rather, sketch out what you'll need for the next list of things, like:
attestation - this user has proven they control this address, different forms
governor - the system messaged this address hash this long ago, this many times
browser - this user tag is signed in with these browser tags
code - the we texted you this many numbers
and then the other functions which you may need in the future, list those here in a brief comment, but don't code them

how does sign-in work, separate 

how dose code work, separate 


database tables:
1 hold simple, atomic facts (rather than the results of logic examining those facts)
	example: one row for sent code, another row for entered code
2 are a ledger that grows, rather than changes
	example: one row for added email, another later timestamped row for removed email
3 hold different kinds of data in a column (rather than having different tables for data)
	example: one table for every way to sign in, that grows as we add new sign-in methods (rather than JOINs between tables about email, sms, x, metamask, etc.)

first, sketch out on paper what the user does and what the system does through valid flows

a user, already signed in, returns to the site

an attacker enters a victims email address many times to get the victim to be sent codes they don't need

a user signes up with email
and then validates that email address

a user, already signed in, 

an anonymous user sets their nickname, and stars something

a signed-in user authenticates with another factor to perform a protected action, like changing sign in
these permissions only extend to their current device
an hour later, their permission level on that device returns to normal

a new user gets codes to validate their email address adn then sms number
the second code they get is code B
the third code they get is 6 digits, not 4

a user signs in on desktop
then on mobile
returns later and is still signed in
then signs out of everywhere on desktop
(what table links a user tag to their browser tags?)
(when does a user get a user tag? how does this work with anonymous users following a feed and renaming themselves?)
(what happens when an anonymous user with data signs up or signs in? this is the cart combined problem)

an anonymous user navigates to the site
their browser gets a browser tag, which is set once, and never changes
the anonymous user stars a feed and sets a nickname, but does not sign up or sign in
it's a shared computer. another user navigates to the site and signs in
they use their account
they sign out
the browser goes back to showing the nicnmake of the anonymous user
a second user signs in
they user their account
they sign out
back to anon user
that anon user signs up
their stars and nickname carry into their new account

a signed in user visits a page that shows them
where they are currently signed in
where they have previously been signed in
with information from the browser's reported query string and geolocation, like city and country



user_address_table

user_browser_table

governor_table
the purpose of governor table is to 

short_code_table

attestation - this user has proven they control this address, different forms
governor - the system messaged this address hash this long ago, this many times
browser - this user tag is signed in with these browser tags
code - the we texted you this many numbers




first, just think about how the short code table works
even before you do the lettered and length variations--imagine all the codes are 6 digits long and random
how does it work that the user has to type it into the same





what prevents a user who has just gotten a 1234 code from trying 10,000 times for guaranteed entry?
turnstile will slow them down
the code will only last 20 minutes
should you also put a governor on trying answers for that code (on a hash of the codeTag in the page)?







== user identity 0.01

imagine this subset
no anonymous users
no email or sms or anything else
it's a user name, and a password
under the hood, there's a browser tag, and a user tag
users can sign up, sign in, sign out
users can delete their account, even--another user can sign up with that name
users can change their user name, their user tag does not change
two different users can share a computer

and a user has a page,
where there is a counter they can change
and a message they can change
(oh, their page also has a card:)

and if they are signed in, it shows where they are signed in
and where they used to be signed in, also
with just this, you can code the list that shows where the user is signed in,
and where they have been signed in

yeah, that's a good user identity 0.01
and also will show you
and then after that, add email
and by adding email successfully, you enable multifactor within the same schema
and email also includes one time codes
and forgot password, that flow

and after that, add sms
which is like another kind of email
and also has forgot password, validate, one time codes, code expiration, rate limiting
lots of advanced stuff

this is your current idea of how you get started with user identity
(1) password, demonstrating linking browserTag and userTag
(2) email, demonstrating one time code validation and forgot password and more
(3) sms, as an alternative additional method to email that you can add without much additional code or schema
















every code could be 4 digits, you now realize
a code only lives 20 minutes or 4 guesses, whichever happens first
it's tied to the browser hash, so a code stealer can't use it
import interactions are authenticated with a strong second factor, anyway

you're not sure how to do code B, code C, so on
because are those specific to the email?
or the browser?
but this might make things harder for the user

what if instead it's six digits and the first two are given
your code is 12-3456
and prepopulated in the box is 12-
or lowercase letters, and then they're before the box

ui7855
gx7588
and it's clear you can' ttype the letters because they're already there and the box is number only
yeah, maybe this is a good design

what if it's a single letter, omitting l and o and g

Your code is v9622 from cold3
and then the box shows the v within the box, but it's fancy css
yeah, this is better design for the user and for implementation

Code H [1234]
Your code H is 1234 from cold3. Don't share it with anyone--they could steal your whole account!





/*
[]rename to like:

[]queryDeleteRow - delete one row if it meets the specified criteria
[]queryDeleteRows - delete all rows that meet the specified criteria
[]querySetCell - change an existing cell to a new value
[x]queryAddRows - add several at once
[x]queryAddRow - add just one of them; these do all the checks first before leading to the same helper
[]queryCountRows - return the number of rows that meet specified criteria
[]queryGetRows - get all of them, sorted
[]queryGetPage - just the desired number, sorted by given title, have limit and offset
[]queryGetSingleRow - use when you know there's zero or one
[]queryGetRecentRow - use when there could be many


[]queryAddRow – Insert a single new row.
[]queryAddRows – Insert multiple new rows in bulk.
[]querySetCell – Update a single column in exactly one row.
[]querySetCells - update all the cells in a column, like setting their hide to 1
[]queryUpdateRow – Update multiple columns in exactly one row.
[]queryUpdateRows – Update one or more columns across all matching rows.
[]queryDeleteRow – Delete exactly one row matching specified criteria.
[]queryDeleteRows – Delete all rows matching specified criteria.
[]queryCountRows – Return the number of rows matching a condition.
[]queryGetRows – Retrieve all matching rows, possibly filtered, sorted.
[]queryGetNRows – Retrieve a limited set of matching rows, sorted.
[]queryGetSingleRow – Retrieve a unique row (or none) matching some condition.
[]queryGetRecentRow – Retrieve the most recent row (or a small set), usually by a time/tick column.
[]queryExists – Return a boolean indicating if any row matches a given condition. (Optional but common)

do not try to build out a complete set, there are two many permutations with a single table
and later when you're doing JOINs the permutations will go geometric
instead, all of these functions are table-agnostic
but made quite bespoke to an application use above in level3
if there's an obvious neighboring use, sure, include it
yeah, that's fine


you'll need a page, database test
and three buttons, Populate, Query, and Clear
yeah, this is a good idea, but don't spend more than a day on it


delete all the rows older than something
invalidate all the rows older than something by changing their hide to 2 or something


[]make it so snippet doesn't run adn doesn't render cloud; this is only local


*/




is this going slow because you don't have automated tests?
remember that you could code some up in example_table





here's how you figur eout the simple universal and correct way to link browser tags and user tags
make user sign up and sign in with password, only
have a message the user can see, themselves
let both anonymous users and signed-in useres see their message
do you need users to pick unique user names to do this? you think so, and that's fine




































/* level 3 query */

settingReadInt, settingRead, settingWrite,

/* level 2 query */

snippetClear,
snippetPopulate,
snippetQuery,

queryFilterSortTop,
queryFilterSortAll,

querySetCell,
querySetCellOrAddRow,

queryGetCell,
queryGetCellOrAddRow,

queryGetRow,
queryGetRowOrAddRow,

queryAddRow,
queryAddRows,

queryCountRows,
queryCountAllRows,
queryDeleteAllRows,












plan out on paper how username and password-based sign up works

sign up
sign in
delete account

browser tag
user tag

user name

a user has a page and a message they can set
other users can see this page, but only the user can change it
you can change your password, but there's no forgot yet

a user's page has a card, which shows their name and when they signed up

a user's page can also have a list of where they're signed in

so from that, tables will probably be
user_password_table - says when p
user_access_table

there is a lot here, actually, even with only one way to sign in (name+password)
you'll figure out how browser tag and user tag are related
how sign out signs out everywhere
how pinia? holds the signed-in status, although you might check it every time in the database anyway






ok, real simple, on paper
imagine a user is already signed in
they have browserTag and userTag assigned
a worker gets a request from a page,
and the page tells the user that they are signed in, and what their userTag is
what is the database table that contains that information

row_tag  row_tick  hide  user_tag  browser_tag  signed_in

row tag, tick, hide are all just standard
user_tag of the user, browser_tag of the browser, signed_in 1 true means that the user is signed in there
browser_tag of the browser and signed_in 0 false means the user is signed out there, and everywhere else, too

so the worker, given a browser tag, wants to determine which user is signed in here
it filters on browser tag, looking at rows in descending order
there could be different users in that row set, of course

so now the worker is looking at a list, most recent first, of:

user_tag  signed_in
<meaningful>

no rows for this browser tag; nobody is signed in

user_tag  signed_in
alice     1 <--meaningful

only a single user has ever used this browser, and she's still signed in

user_tag  signed_in
alice     1 <--meaningful
alice     0
alice     1

here, just alice is using this browser, signed in, out, then in again
alice is signed in here

user_tag  signed_in
alice     0 <--meaningful
alice     1

nobody is signed in, alice has previously signed in, but signed out
this is good, that we still have data of what happened in the past here, because if alice signed up with method X, the sign in form can preference or hint at method X

user_tag  signed_in
bob       1 <--meaningful
alice     0
alice     1

after alice signed in and then out, bob signed in. bob is signed in here

user_tag  signed_in
alice     1 <--meaningful
bob       0
bob       1
alice     0
alice     1

alice signs in and out, bob signs in and out, then alice signs in


ok, so keeping with the simplification that a sign out signs out everywhere
looking at this, filtered for one browser, you will run into useres who look signed in here, but somewhere else, they signed out
you almost need a separate table of sign-outs:

sign_out_table
row_tick user_tag

so this is just the list of times when alice or bob last signed out
so here's how you use those?
you look at the sign-in table for this browser, to get the users who are currently signed in here
then you go to the signed out table to invalidate sign ins for alice that are older than her most recent sign out
wow, that's already a quite complex query

you just realized when you're doing the super authentication that only lasts 1 hour, or wahtever, and only exists on one browser, you can do that like this:

user_tag  signed_in
alice     2 <--meaningful
alice     1

assuming that the time now is within an hour of the 2 row

ok, back to one table
here's how the "who is signed in here?" worker figures that out
filter to just rows about this browser tag
from that, get all the users who have done something with this browser here

now you have a list of users
you go back to the table and pull all the rows about all of those users

user_tag  signed_in  browser_tag
alice     1          here
alice     1          elsewhere
bob       0          elsewhere
bob       1          here

users who are most recently signed in 0 you exclude--it doesn't matter whether they signed out here or elsewhere--they can sign in again

user_tag  signed_in  browser_tag
alice     1          here
alice     1          elsewhere

what if there's a separate table of user tag, and when they last signed out
so from the first table, you look at who's signed in here
that is, browser tag is here, signed in is >0, you get a list of users
you go down that list most recent to earlier, looking user by user at sign-outs in the other table. the first one you find who's signe din here and not signed out after that, is signed in here

ok, so that's pretty not simple, and you have hopeful doubt, rather than confidence, about its workign and ramifications

assuming private devices, it's also acceptably low number of round trips
but omg, you can't do this simple first thing with one query?!

here it is again, one table, a series of queries
pull all the rows about this browser tag and sign-ins
from that, you have a list of users who are or have ever signed in here

then do the second query--all sign out records of all of those users, everywhere
now you're piecing through that in the worker, i guess?
you go user by user, in order of signed in here
and then look at that user's most recent sign out, anywhere
the first signed in here user who doesn't have a more recent signed out, anywhere, is signed in here








what if the ledger design is a mistake?
what if instead, you should keep an actual unqueryable but free to blather ledger
and do things in the database by editing
like a normal DBA

(or, you actually use the row invalidation thing) <--trying this method today
(or, you have both--a table that gets edited, to be fast and final, and alongside those, tables that are logs essentially, which you use to infer things and audit things--they can grow big and slow)

ok, what's that look like
there's a table that maps browser tag to user who is signed in here
there can only be one browser tag, so there's only one user who can be signed in
when a user signs out, we have to find all the browser tag rows where they are signed in, and sign them out of all of those
this is a bigger operation than just adding a new row to create a command and record to sign out





what if you hide rows as you go

othe ridea is to limit the number of places a user can sign in

but you're feeling better about this design now, though

user_browser_table - tells where users are signed in to what browsers
user_identification_table - tells how users prove they are who they say they are, with email, sms, metamask, two factor app codes, all that

also, let's design assuming two things
-supabase api always works
-two or more supabase commands do complete as a transaction (there isn't the same user writing a similar thing at the same time)
at this point, those assumptions are necessarily, essentially, to be able to move forward





browser_table







user_stage_table
user_tag
stage

records a user's lifecycle
0 does not actually exist in this table or anywhere else, reserved
1 new anonymous user we're letting leave traces, but who has not signed up yet
2 regular signed up user in good standing
3 account hidden, could be unhidden
4 account closed
notice how permissions (creator, staff) are reflected elsewhere
notice how reason for deleting (banned, user left) are also not reflected here



user_name_table
user_tag
name_text - user name rendered, as on a page
route_text - user name as in a route, all lowercase

links page user name, route user name, and user tag
records changes to those in ledger format


you just realized that in these two, changes are rare
so you can query the most recent row
adn don't have to worry about hiding previous rows
this is actually a lot easier a task than browser_table!



later realized, an account could also be temporarily suspended by staff
while we clear something up with a user, who, if in chat oob, promises to not do that again
so both closed and hidden can be done by user or staff





connect these above and below:
right now just for users signign up and signin in
they don't have routes or pages yet
also, at this point, user names are lowercase routes





super permission hour:



first factor: (fans)
- browser tag
- no expiration

second factor: (creators, or a destructive operation)
- browser tag
- user tag, signed in at that browser
- ip address, according to connection (trustworthy)
- user agent string, according to headers (less trustworthy)
- OpenGL hardware, according to browser (less trustworthy)
- one hour expiration, according to server clock (trustworthy)



imagine you have a multipurpose table:

trail_table

	row_tag
	row_tick
	hide

	hash

and indexed on tick and then hash, and hash and then tick, both directions

rows older than 10 days are discarded by a github action cron endpoint
you can always hash any amount of different things down into a single value
so you can use this, alone for things that need to be recent, or not recent
and to figure out if they are recent enough
or how many times they happened in a time period within the last 10 days

when a user super authenticates, you can hash together their:
1 browserTag
2 userTag
3 ipAddress
and put it in the trail table
when seeing if a request has such status, you can search for that hash in the last hour

fancier, more brittle, not much stronger would hash
1 browserTag
2 userTag
3 ipAddress, trusted from cloudflare
4 user agent string, according to headers browser sent
6 opengl renderer and vendor, according post body browser sent
sure, whatever








maybe, not all tables are ledger
settings_table already isnt
browser_table, which links browser and user tags
needs to be definitive as it controls returning logins, lots of security there
needs to be quick as the client plugin will get the info an dthen render one whole set of components or another
this is hi1
which needs only to know if a user is signed in here or not

actually, it can do that pretty fast with the current ledger design
so maybe keep it

when do we create the anonymous user?
we could when we first see a new browser tag; we'll have a lot of them
we could instead when a new person first clicks Follow, or sets their nickname
yeah, you like that better, less clutter in the database



totally make the api_table
which is a history and audit of every request and every response to every api
so you can see what worked and what didn't work
and 











/*
ttd february
ok, if you're going to refactor these so querySetCellOrAddRow and queryGetCellOrAddRow and surrounding
you need to write some tests
to start quickly, just get node's $ yarn snippet
you already have $ yarn test running ./test.js
have that call snippet
get snippet here
then break that out into ./test-database.js and $ yarn database
rename that to testDatabase

most of these tests use example_table, of course



actually this get or add is already two calls, is only used for settings_table, so just []move it to level3
*/

//[ran]
/* made for settings, not used
export async function querySetCell({table, titleFind, cellFind, titleSet, cellSet}) {
	let row = await _querySetCell({table, titleFind, cellFind, titleSet, cellSet})
	if (!row) toss('row not found')
}
*/
//[ran]

/*
//ttd february--these are only used by settings, move them to level3
export async function querySetCellOrAddRow({table, titleFind, cellFind, titleSet, cellSet, rowAddDefault}) {
	let row = await _querySetCell({table, titleFind, cellFind, titleSet, cellSet})
	if (!row) await queryAddRow({table, row: rowAddDefault})
}
async function _querySetCell({table, titleFind, cellFind, titleSet, cellSet}) {
	checkQueryTitle(table); checkQueryCell(titleFind, cellFind); checkQueryCell(titleSet, cellSet)
	let database = await getDatabase()
	let {data, error} = (await database
		.from(table)
		.update({[titleSet]: cellSet})//write cellSet under titleSet
		.eq(titleFind, cellFind)//in the row where titleFind equals cellFind
		.select()//return the updated rows
		.maybeSingle()//data is the updated row, null of no rows matched, error if 2+ rows matched
	)
	if (error) toss('supabase', {error})
	return data//data is the whole updated row
}
*/

//[ran]
/* made for settings, not used
export async function queryGetCell({table, titleFind, cellFind, titleGet}) {
	let row = await _queryGetRow({table, titleFind, cellFind})
	if (!row) toss('row not found')
	let cellGet = row[titleGet]
	checkQueryCell(titleGet, cellGet)
	return cellGet
}
*/
//[ran]
/*
//get the cell under titleGet from the row where titleFind is cellFind, adds a default row if not found
export async function queryGetCellOrAddRow({table, titleFind, cellFind, titleGet, rowAddDefault}) {
	let row = await queryGetRowOrAddRow({table, titleFind, cellFind, rowAddDefault})
	let cellGet = row[titleGet]
	checkQueryCell(titleGet, cellGet)
	return cellGet
}
*/

//[ran]
/*
export async function queryGetRow({table, titleFind, cellFind}) {
	let row = await _queryGetRow({table, titleFind, cellFind})
	if (!row) toss('row not found')
	return row
}
*/
//[ran]
/*
//get the one row with value cellFind under titleFind, add the given default row if not found
export async function queryGetRowOrAddRow({table, titleFind, cellFind, rowAddDefault}) {
	let row = await _queryGetRow({table, titleFind, cellFind})
	if (!row) {
		row = rowAddDefault
		await queryAddRow({table, row: rowAddDefault})
	}//^ lots of discussion with chat about the race condition here, and no good fix: .upsert() can do it in one statement, but will modify the row on conflict, not return it; .insert(..., {ignoreDuplicates: true}) works but means we have to call out to supabase twice every time
	return row
}
*/
/*
//in table, look at column titleFind to find one row with value cellFind, undefined if not found
async function _queryGetRow({table, titleFind, cellFind}) {
	checkQueryTitle(table); checkQueryCell(titleFind, cellFind)
	let database = await getDatabase()
	let {data, error} = (await database
		.from(table)
		.select('*')//select all columns to get the whole row
		.eq(titleFind, cellFind)//find the row where titleFind equals cellFind
		.maybeSingle()//data undefined of no rows match, error if 2+ rows match
	)
	if (error) toss('supabase', {error})
	return data//data is the whole row
}
*/







//ttd february--have all of these expect a table that starts with the standard three rows; update settings to do that, too. then, the two above replace the two below entirely

//[ran]
/*
//add one new row to table like {title1_text: "cell1", title2_text: "cell2", ...}
export async function queryAddRow({table, row}) {
	await queryAddRows({table, rows: [row]})
}
*/
//[ran]




//[]
/*
//get the most recent row in table where cell is under title, or undefined if none found
export async function queryFilterMostRecent({table, title, cell}) {
	return await queryFilterSortTop({table, title, cell, titleSort: 'row_tick'})
}
*/
//[ran]
/*
//get the one biggest titleSort row that has cell under title, or undefined if none found
export async function queryFilterSortTop({table, title, cell, titleSort}) {
	checkQueryTitle(table); checkQueryCell(title, cell); checkQueryTitle(titleSort)
	let database = await getDatabase()
	let {data, error} = (await database
		.from(table)
		.select('*')//select all columns to retrieve entire rows
		.eq(title, cell)//filter to get rows where title equals cell
		.order(titleSort, {ascending: false})//sort rows by titleSort in descending order
		.limit(1)//just the winning row, probably using to get the most recent row_tag
	)
	if (error) toss('supabase', {error})
	return data[0]//data is an array with one element, or empty if none found
}
//[ran]
//filter table to rows with cell under title, and return sorted by titleSort, biggest first, or [] if none found
export async function queryFilterSortAll({table, title, cell, titleSort}) {
	checkQueryTitle(table); checkQueryCell(title, cell); checkQueryTitle(titleSort)
	let database = await getDatabase()
	let {data, error} = (await database
		.from(table)
		.select('*')//select all columns to retrieve entire rows
		.eq(title, cell)//filter to get rows where title equals cell
		.order(titleSort, {ascending: false})//sort rows by titleSort in descending order
	)
	if (error) toss('supabase', {error})
	return data//data is an array of objects like [{'row_tag': 'nW83MrWposHNSsZxOjO03', ...}, {}, ...]
}
*/







//-- ttd february: see if you can get just a half dozen useful and commonly used query functions--then you probably don't even have to write tests!




this design sketch came together pretty well!:

it's really hard to refactor these without tests
what if you just had little noop tests beneath each one, you'd turn them on and off individually
and they'd use example1_table, which is wide, and example2_table, which is narrow
and i guess each one has a _version which takes

testClock

export async function querySomething({table, row, titles, clock}) {
	//if no clock, then we
	const {Now, Tag, database} = getClock(clock)
	//if clock is null, then you get normal actual now and tag
	//if clock is not null, then you get fake

	//clock also gives you the real or not real database


}
icarus won't be able to run these tests, they're for $ yarn test

noop(async () => {
	
	const clock = testClock({ago: 3*Time.year, tag: ''})


	clock.forward(2*Time.hour)



})

oh yeah, also, if there's a clock, it automatically



what if 
















noop(`
-- list all the tables, and all the indices
SELECT tablename FROM pg_tables WHERE schemaname = 'public';
SELECT indexname, indexdef FROM pg_indexes WHERE schemaname = 'public';

-- see what columns a table has, and what their type is
SELECT column_name, data_type FROM information_schema.columns WHERE table_name = 'my_table';

-- see what indices a table has, and delete one
SELECT indexname, indexdef FROM pg_indexes WHERE schemaname = 'public' AND tablename = 'my_table';
DROP INDEX IF EXISTS index_name;

-- rename a table, column, and index
ALTER TABLE current_table RENAME TO renamed_table;
ALTER TABLE my_table RENAME COLUMN title1 TO title2;
ALTER INDEX current_index RENAME TO renamed_index;
`)


/*
ttd feburary, let's rename things

browser_table_browser_tag_index




ALTER INDEX browser_table_browser_tag_index RENAME TO browser_table_index1;















	access_table_pkey

browser_table_index_1
	browser_table_pkey

	example_table_pkey

hit_table_index_1
	hit_table_pkey

route_table_index_1
route_table_index_2
	route_table_pkey

	settings_table_pkey --stays named table!

trail_table_index_1
trail_table_index_2
	trail_table_pkey



ok so settings is the only one
so maybe you keep them named _table
and make those three required on all tables, yeah






hits 1420






settingReadInt
	settingRead
		queryGetCellOrAddRow (used once)
			queryGetRowOrAddRow (used once)
				_queryGetRow
				queryAddRow

		settingWrite
			querySetCellOrAddRow (used once)
				_querySetCell
				queryAddRow








//ttd february--factor ^ as queryUpdateCell, and have queryHideRows call it. don't worry about multiple matches as only settings cares about that, too

/*
for read, find the most recent visible row with title: 'setting_name_text', cell: 'hits'
if not found, add a row

for write, find the same way; if not found, add a row
querySetCell
then set a cell, how do you do that?


*/









	/*
	ttd february, now that you only have 6 query functions, consider the refactor like:
	let row = await queryTop({table: 'settings_table', cell: {setting_name_text: name}})
	yeah, looking at that now, maybe not!
	*/


//ttd february, write these ^ maybe also queryUpdateCells, which queryHideRows would use, and then stop exporting getDatabase. oh also, you can sneak a direct database connection into level3 by exporting the test clock, and that's ok, i suppose, except the query check functions are here, and you want to not have to export them, also--yeah, cleanest is not exported is getDatabase, the test clock, all the query check functions--really only touch the database directly in level2!







async function query_browserToUser({browserTag}) {//level2-style up here in level3; this query is bespoke with two eq and a gt
	checkQueryTag(browserTag)
	let database = await getDatabase()
	let {data, error} = (await database
		.from('browser_table')
		.select('*')//retrieve the matching rows
		.eq('hide', 0)//only rows that are not hidden
		.eq('browser_tag', browserTag)//rows about this browser
		.gt('signed_in', 0)//that describe a user signing in, gt is greater than
		.order('row_tick', {ascending: false})//most recent first
		.limit(1)//just one row
	)
	if (error) toss('supabase', {error})
	return data[0]//returns the row, or undefined if no row
}








//                                               _        _     _      
//   __ _  _____   _____ _ __ _ __   ___  _ __  | |_ __ _| |__ | | ___ 
//  / _` |/ _ \ \ / / _ \ '__| '_ \ / _ \| '__| | __/ _` | '_ \| |/ _ \
// | (_| | (_) \ V /  __/ |  | | | | (_) | |    | || (_| | |_) | |  __/
//  \__, |\___/ \_/ \___|_|  |_| |_|\___/|_|     \__\__,_|_.__/|_|\___|
//  |___/                                                              

//when did we last do this? how frequently have we done this recently?









/*
ttd feburary, let's rename things

browser_table_browser_tag_index












*/










/*
ttd february, below, you want to refactor this into a tree such as:

queryUpdateCell, used by settings
queryHideRows, commonly used
(both call down to the same)
queryUpdateCellsVertically
*/

//here are two older functions, for reference, that some new functions we write will replace the functionality of:

/*
//hide rows in table with cellFind under titleFind, changing hide from 0 to hideSet like 1
export async function queryHideRows({table, titleFind, cellFind, hideSet, clock}) { const {Now, Tag, database, context} = await getClock(clock)
	checkQueryTitle(table); checkQueryCell(titleFind, cellFind); checkInt(hideSet, 1)
	let {data, error} = (await database//this call doesn't return count, so we look at data.length below
		.from(table)
		.update({hide: hideSet})//hide rows that match:
		.eq('hide', 0)//not yet hidden, and
		.eq(titleFind, cellFind)//cellFind under titleFind
		.select('*', {count: 'exact'})//get the rows we changed, count exact to count rows that matched our query
	)
	if (error) toss('supabase', {error})
	return data.length
}
//ttd february--refactor so queryHideRows and queryUpdateCell both call queryUpdateCells; not sure what's common and specialized when you do that
export async function queryUpdateCell({}) {}
export async function queryUpdateCell_newForSettingWrite({table, titleFind, cellFind, titleSet, cellSet, clock}) { const {Now, Tag, database, context} = await getClock(clock)
	checkQueryCell(titleFind, cellFind); checkQueryCell(titleSet, cellSet)
	let {data, error} = (await database
		.from(table)
		.update({[titleSet]: cellSet})//write cellSet under titleSet
		.eq(titleFind, cellFind)//in the row where titleFind equals cellFind
		.eq('hide', 0)//that is not hidden
		.select()//return the updated rows
		.maybeSingle()//make data the updated row, undefined of no rows matched, error if 2+ rows matched
	)
	if (error) toss('supabase', {error})
	return data//data is the whole updated row, or undefined if not there so you should add it
}
*/

//now, let's write the three new ones, as follows:
/*
queryUpdateCellsVertically will select rows, and then change all the cells under a given title to a new given value
this generalized use case is then specialized by these two functions, which call that:
queryHideRows selects the rows, and changes the hide column to the given number
queryUpdateCell selects a single row, if present, and changes the given column to the given value
*/










the idea of how you approach
start with the schema
the very bottom, upwards
then the functions that access that table
place data in supabase manually
code the read pathways
then after all that is done, do the edit and write pathways

previously you've been thinking write first, smallest possible loop
but those get too big and too complicated when you switch from simple examples to real interactions


name_table

row_tag
row_tick
hide

user_tag

normal_text --reserved route, lowercase
formal_text --chosen and correct route, chosen case
page_text --chosen and correct name, only for page

that's the schema, now here are the functions
a GET request has come in--do we have a user by that name? is the case correct, or should we redirect?
a user is trying to take a name--is it unique for them to take?

{userTag, nameNormal, nameFormal, namePage} = await lookupUserTag({userTag})
{userTag, nameNormal, nameFormal, namePage} = await lookupUserRoute({requestedRoute})
lookupUserName({nameNormal nameFormal or namePage})

actually could be just two functions
{userTag, nameNormal, nameFormal, namePage} = await getUserName({
	userTag//get information about this user
	requestedRoute//to serve a GET request, find out if there's a user here
	nameNormal//find out if this route is taken already
	nameFormal
	namePage//find out if this name is taken already
})
await setUserName({userTag, nameNormal, nameFormal, namePage})//makes a new row
do you need to hide the older ones?

indices are, you're going to lookup (all these as normal by hide and sorted tick)
normal_text
page_text




takeUserName({userTag, nameNormal, nameFormal, namePage})//you've already checked for uniqueness in this same call, use to establish a user at a route for the first time, or change just nameFormal without changing the route, or just the display name on the page without


getUserName -- returns {userTag}, or falsy if available
getUserRoute({requestedRoute}) -- returns {userTag, nameFormal, nameNormal, shouldRedirect} or falsy if available
takeUserName({userTag, nameNormal, nameFormal, namePage})//doesn't check for duplicates, does invalidate previous rows. use this when a user signs up, changes their name,
or changes something that doesn't actually affect routing, like


nameGetPage(raw)
nameLookRoute(raw)//true if yes, available so you can take it

nameLookupRoute



other user stuff, like status, avatar, goes in profile_table
but we do keep the user's name on the page here
because it's closely related to their route
and because we also want to enforce uniqueness there--we can't let two users both call themseves Tokyo❤️Girl, for instance



actually, maybe you should have










simpler browser_table

row_tag
row_tick
hide

browser_tag
user_tag

and that's it

(*) when a new person submits information, we make them a user tag, and sign them in at their browser tag

browser_tag  user_tag
----         ----
browser1     user1

(*) that user finishes signing in, or otherwise gains additional permissions; browser_table doesn't care

(*) that person goes to a different computer,
which immediately gets a new browser tag
there, they prove they are the same person as before, we sign them in

browser_tag  user_tag
----         ----
browser1     user1
browser2     user1

note how user_tag cannot be unique, as two rows with the same user tag are valid and how we keep the user signed in two places

(*) on the second computer, browser2, the user clicks sign out
we hide all the rows with user tag user1
(note that we don't record a timestamp of when this happened, nor information about where it happened, which we're doing in this ultra-simple design to keep it simple)

browser_tag  user_tag
----         ----
(no visible rows)

(*) the user returns to browser1, and signs back in again

browser_tag  user_tag
----         ----
browser1     user1

(ok, so that's all fine; now imagine there's another user who starts out on browser2)

(*) a new person goes to browser2, and Follow

browser_tag  user_tag
----         ----
browser2     user2

this is a real user tag, and user2 is signed into browser2. they can't sign in anywhere else, nor sign out, of course, until they create a real account, which they won't do yet

(*) an existing user goes to browser2, and signs in

browser_tag  user_tag
----         ----
browser2     user2



hmm, maybe there is a level
0 sign out
1 provisional (clicked Follow or entered a phone number to get a code, didn't do anything more. user can pick up wher they left off by returning to this browser. they can't sign out, though, because they're not really signed in)
2 actual (full account signed in. the user can sign out)
3 dual factored (just for the next hour, and just on this browser, the user has elevated permissions)

and, imagine we never hide rows, either! (making one part simpler and the other more complex)

and then imagine a cluttered table, and we know a browserTag, and want to know whos signed in here


ok, actually, a sign out does need to hide rows of previous sign ins

(yeah, this is all interesting--you haven't figured it out yet!)






slept on it
if it's simpler (but you don't think it is) you could blow away a browser's provisional user if some other user signs in there
provisional useres are great to help new people sign in for the first time
but in a corner case that's more complex than that, it's actually a little weird if you're signing out and then there's still some fragment of something different left behind
the most common cas when this will happen is it's the same human, who signed up and in disjointedly
so yeah, you probably should blow away

for logging, you want to have
hit_text as a final notes column for lots of these
when a table is about the user tag, exclusively, you can still have the browser tag where they did it in hit_text
hit_text then includes all the columns of hit_table, but as json
this is a good idea



ok, yes, i think we are on the right track
i did some more thinking along these lines, and will share that now

before i get started, you mentioned Sessions
i do want to say that our web app design is already, perhaps, not typical in that our framework does not have, nor allow, cookies or other common methods to create an automatic session
here is what we have:
- each browser always has a unique and unchanging browser tag
- the database
there's nothing else in the middle. no cookies, no memcache, no KV store, etc. we can tell a request is from the same browser as before (a moment before, a year before) because the incoming POST will include a browser tag that we have records about in the database
my hope is that this limitation is freeing, in simplicity, rather than confining, as we come up with this design

first, in the patterns set up by our DBA, tables in this app have three default "margin" columns:
row_tag
row_tick
hide

each row, when it is added, gets a guid that identifies the row, set in row_tag
this is also the primary key, which must be unique
these tags are always there, and we could use them in the application, but have not needed to do that yet
instead, our application code so far is ignoring them

row_tick is the unix epoch timestamp when the row was added
in other tables in our application, we are using this timestamp
if the row is about something that happened, we can know when the event happened by querying row_tick
we don't have to make a separate column for like event_time_tick or something
row_tick also lets us sort rows in chronological order
other tabes use this to find, for instance, the most recently recorded row that is visible (described next) and fits other criteria
we're finding this to be a useful pattern with our tables *a lot*!

the third margin column is hide
by default, hide is 0, meaning the row is visible
instead of deleting rows, we hide them, as a way to audit things later outside of the context of the normal and automatic use of the running app and system as a whole
our DBA set up the hide pattern as an insurance policy against something going wrong, and then it being very difficult to figure out what happened, looking at the current state of the database

hide also means we usually do not edit rows
instead, we make a new row (recording the timestamp row_tick of the edit)
and hide the previous row the new one replaces

ok, so as we design browser_table in this conversation, know that those are the first three margin rows
we can follow the patterns of their use
and also use them to avoid creating columns after unnecessarily

ok, now ill revisit my thinking on the browser_table columns after the starting margin columns, which may be:
browser_tag - identifying the browser and device, like "phone", "laptop" for the example ill get to in a moment
user_tag - identifying the user as soon as they start giving the system information, even before completing sign up, like "alice", "bob" in the sketch below
hide - an enumeration that says what happened, such as:
0 signed out
1 provisional user (provided information, but has not yet completed sign up to be able to sign out or sign in on this or any other device)
2 actual user (traditional full user who can reset their password and all the common user stories)
3 sudo authenticated--not sure on this one, but including it because my hope is we find a design which easily clearly simply extends to also cover this. a user on a device may want to do some elevated permission tasks, like changing a password or moving funds. to do this, they'll complete some two factor authentication step, and then be sudo authenticated--but with limitations that are unique to this level. their sudo-ness will only be on this one browser (identified by browser tag). and, it will only last one hour (start time identified by row tick)

ok, so, from all that, now i'm sketching out scenarios of two users with two devices, doing different things. neither of these users are attackers--this is all happy path planning. also, while this scenario explores some edge cases, they will likely be not uncommon! ok, here's an example simulation

browser_tag, user_tag, level, (event description):
phone, alice, 1, alice on her phone starts the sign up process
phone, alice, 2, and finishes it, creating a full regular account with a password and recovery options
laptop, alice, 2, alice goes to her laptop, and signs in there. now she's signed in on both devices
phone, alice, 0, back on her phone, alice clicks sign out

a design choice that has come from management is that when a user signs out anywehre, they are signed out everywhere, as a security precaution (rather than having two sign out buttons, that a user may click the weaker when they are looking for the stronger--all sign outs are strong)

so, i think (do you agree) that the system does the sign out as follows:
add a row to record the sign out, but just for audit: phone, alice, 0
hide all rows in the table about alice!
(so, we could make the phone,alice,0 row visible and then hide all rows (as an alice row it will be hidden)
or, we could make that row hidden to start, and then hide all the others--both have the same result)

alice and bob are partners and share a laptop
bob hears about the site, and wants to sign up to, grabbing the laptop

laptop, bob, 1, bob begins his own sign up process

bob doesn't finish, though, and next alice comes to the laptop, visits the site, and signs in

laptop, alice, 2

now the steps the server performs looking at this table to see who is signed into this browser tag will see the following
looking at only visible rows, and filtered to the laptop browser tag
there will be two rows
bob's provisional presence, at an earlier time, recorded by 1
alice's actual presence, at a more recent time, recorded by level 2

it's correct for the handler to answer that at the laptop, alice is signed in
so it must either pick the highest level? or the most recent time? here is a specific question i need your help with, to get the logic simple and correct and certain, even against all real-world permutations and possibilities!

continuing our same scenario, alice finishes with the site, and signs out
laptop, alice, 0, hidden
the handler creates that row, and also hides all alice rows, for all browser tags, laptop and any others

now, bob comes back to the laptop, where he most recently started signing up
his stuff is there, because a request for server side code using this table to answer a page's questino "here's my browser tag, what user tag is here?" finds the laptop,bob,1 row, and answers bob, at level 1 (provisional)

so all of that is an example of a single sceario

so here's what i need your help with:

(1) is my reasonging here correct? have i missed something with the logic of this design? some simple way a user can mess things up for themselves? some way that a user can create bad data in the table which will affect themselves or the app as a whole? (i need to be sure neither of these things, especially the second one, is possible!)

(2) as a human, i can sketch out one scenario in a few minutes, an dthen a second in a few more minutes. i can try to guess at what some people on some devices might do next, and what the database table will look like as a result of those actions. and, at each step, when a request comes in to find out what user is at a given browser, what application code will do to look at the table and produce some answer to that question. but, i can't imagine twenty scenarios all at once, or easily be certain that my design covers all possible scenarios. so, that's what i need your help with--finding mistakes in my reasoning. following the logic of my rules, but maliciously, to get the database into an unusual state which will cause next requests to not work the way we want them to

(3) if this design works, how would it work to build upon it and also have level 3 sudo? i've intentially left it out above, as i want to get the simple part working first. it's not absolutely necessary for the sudo access system to use browser_table--lots of user permission things will be handled by other tables and logic, either way

ok, that's my thinking, and my questions



ok, my feedback:

these are good and valid suggestions, but are not within the scope of our discussion
i need to get the columns and cells of browser_table correct
and also make sure the steps that server code performs upon requests is correct and valid
that's the part im working on (columns, cells, steps) those three

yes, we can trust the clock
we can trust that a single set of steps to handle a request are completed atomically
we can trust that credentials are provided accordingly
we don't have to worry about race conditions within steps
we *do* need to make sure our design prevents things getting out of sync between events done at human timeframes (minutes later, hours later)

you say "Use row_tick as the sudo start time and then add logic in your application to check if the current time is within one hour, or (make another column)" yes, i want to use row_tick for that. i do not want to make a new column unless necessary, as we are looking for a simple design that handles happy and edge cases, guards against malicious activity, and is small enough to easily reason about

you say "Ensure that your code routinely checks"--this type of feedback is not helpful, for two reasons (1) our task here is to set the exact steps, at a high level, the code performs, not offer a platitude about it being vigilant, and (2) there is nothing here that runs "routinely"--rather, requests come in from browsers, telling us their browser tag, or taking an action related to a user providing information to sign up, signing up, signin in, or signing out. these POSTs are the only thing that happens, and when they do, an untrusted page can say whatever it wants, and then our trusted code on the server to handle that request can validate that data, using the exact rules we come up with, and read and write to browser_table. **that's it, and we have to be specific and complete and stay within that!!**

you say "Testing Is Key: Since it can be hard to imagine every possible sequence" i know that--i need your help thinking of additinal sequences, dozens perhaps, even if we can't come up with every possible one, and then confirming that no sequence jumps the logic we come up for the event handlers to product a result, for the user, or in the table, which is outside our expected and intended behavior.

so, based on all that, please, let's try again



yeah, chat couldn't do it


ok, here's new and your own thinking

to sign out, you make a new row level 0
and the immediately hide all rows about that user, which also hits the row you just made

you can do sudo level 3
if that's the most recent thing, and it's an hour+ old
then do the cleanup where you hide rows about old sudo
you think that existing sign-ins level 2 will show forth, then
you could do this for just that user, or really for all useres, probably also fast
but make sure you have an index for that
and then if you pulled an expired sudo, you hide all expired sudos, and then repeat the search
so we're slowing down not every request, just the requests for expired sudos





















these are good: turn into documentation vvv
/*
notes excited about trailtable
and, about anything! because it's usees hashes!

too late - codes expire in 20min and we sent that one to you 25min ago
too soon - we just sent you a code 30 seconds ago; try to look for it again. if you really can't find it, we can send you a new one after 5 minutes
too frequent - we can't message that address anymore because we sent it 10 codes in the last 24 hours

ok, that one, how do you tell them when they can come back?
like, you could say come back tomorrow, for sure
but it's also possible stuff will work sooner, as soon as the oldest code in that set recedes over the horizon

well, you could do it like this:
if you've sent 10 codes in the last 24 hours (trailCount)
then we won't let you send another one for 6 hours (trailRecent)
yeah, you're fine
no--nevermind, three hours later there aren't 10 codes anymore, so the user can send more
and, as written, we can't tell them when they can try again
so you may need another query, that counts within a recent stripe of time, or something

this may not matter because the person who hit this limit likely did a whole bunch, in a row, very recently
so telling him he has to wait 24 hours to com eback is likely true
and even if its not, even if it's actually 12 hours, we're trying to slow that person down at this point

ok thought of how you do it
as soon as you detect the overflow (10 codes in 24 hours)
you record another row, representing the cool-down block
that block says come back in 24 hours
and then actually just lasts for 20 hours
and then when checking if an address is cool to message, you look for
1 current block in effect, searching for that hash value, and
2 frequency at limit, so make a new block right now!

extra things later you realized you can us ethis for:
-a user has authenticated themselves at a single browser for an hour of super user permissions
-
*/



















// ~~~~ here we are doing the work behind CodeComponent ~~~~































































fin
