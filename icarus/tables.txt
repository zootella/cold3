









[I] design

we think of the database as a stack of grids of letters and numbers
the vibe here is not ORM; it is CSV

tables are ledgers; we append to them
instead of deleting a row, mark it as hidden


database tables:
1 hold simple, atomic facts (rather than the results of logic examining those facts)
	example: one row for sent code, another row for entered code
2 are a ledger that grows, rather than changes
	example: one row for added email, another later timestamped row for removed email
3 hold different kinds of data in a column (rather than having different tables for data)
	example: one table for every way to sign in, that grows as we add new sign-in methods (rather than JOINs between tables about email, sms, x, metamask, etc.)


[I] types and names

our tables do everthing with just a small handful of postgres types,
and our conventions for column titles identify what kind of data columns have:

example2_table            table names end _table, lowercase and numerals ok

row_tag         CHAR(21)  a globally unique tag to identify this row
row_tick        BIGINT    set when we added the row
hide            BIGINT    0 to start, nonzero to ignore this row in regular use
                          ^ most tables start with these three columns

password_hash   CHAR(52)  52 characters of a sha256 hash value encoded to base32
user_name_text  TEXT      text which can be blank or long

_tag, _hash, and _text are strings; everything else must be an integer
a column which can be a tag or blank is _text
as is a column which can be text or numerals

all numbers are BIGINT, even if we only planning on storing 0 or 1 there
BIGINT has a larger range than JavaScript's Number.MAX_SAFE_INTEGER

we intentionally avoiding PostgreSQL date, time zone, duration, and UUID types
ARRAY and JSON might be useful in the future, but are not in use now
we use cloudflare's clock, Date.now() in a worker, and no clock from Supabase or PostgreSQL

row_tag is the PRIMARY KEY of every table, intentionally avoiding SERIAL,
and guaranteed unique, even though we never query on it
all columns are NOT NULL to make things simpler



[I] features

we create indices, including multicolumn indicies,
that match common queries to make them fast
there are no foreign key relationships, which establish constraints between tables,
and don't help performance




[I] intentionally avoiding, simplicity

there is no ORM, avoiding Sequelize, Prisma
these add complexity and developer learning curve
some involve vendor tie in, monetary cost, and deplatform risks
they can only make things slower, not faster, for the user
they make it harder to count and follow individual queries,
which is important in our stack where each query costs 150ms
we're thinking about the database as a grid of text and numbers, not objects

all in all, the idea is to keep our use of the database simple enough that we can
reason about it as just a grid of text and numbers, and nothing is tied to
Supabase or PostgreSQL--a migration to SQLite, even, would be easy









[I] concessions, here are some limitations with this design that we know and accept:

a worker's call to supabase takes ~100ms
some api handlers may involve a handful of these
we accept that this can make some user clicks take nearly a second to complete, a noticable delay
to lesson this impact on the user,
hello1 and hello2 are split apart,
and we use Pinia to prefetch and cache data, so that many user clicks, even route changes, are instantaneous
also, many clicks that involve a lot of queries are about tasks that are either rare, or slow anyway
like changing your user name (rare), or verifying an address (slow)

[I] assumptions, here are the assumptions we need to make to move forward swiftly with this design:

- the supabase api and workers' connections to supabase will be reliable, and the supabase api is error-free. we assume that if a call succeeds, it did what it said it would, without checking
- if neighboring lines in a worker make two edits to the database, there won't be a change to the database between them
- if information in the database enters an unexpected, should-be-impossible state, code is conservative enough that this won't break the app, and later changes could heal the data

essentially, i've found it's not possible to code with the database to the same level of perfection as dealing with other parts of the system
to be able to move forward, a level of trust is needed, expressed in these concessions and assumptions
















make sure postgresql has the default utf-8 character encoding with a sql statement like this:
SELECT pg_encoding_to_char(encoding) AS encoding FROM pg_database WHERE datname = current_database()
ran this in supabase's sql editor, and the result is "UTF8"


supabase is full of darkpatterns to turn on row level security
because that's how they get you
turning off rls is fine, and common when server code has exclusive access to the database



talk about level3
where functions are specific to the applications use of
one table or several
and below that, level2
where functions work generally on any table
to be useful in potentially several places to code above
all tables start out with the margin columns, even if the table doesn't need or use them
functions assume those columns and work with them









long chat about transactions that ended up with this

const sql = `
	BEGIN;
	INSERT INTO first_table (column) VALUES (quote_literal(${val1}));
	INSERT INTO second_table (column) VALUES (quote_literal(${val2}));
	COMMIT;
`
const { data, error } = await supabase.rpc('execute_sql', { sql })

imagine the database only makes sense when both, or neither of these rows are added
if one row is added, and the other one not there, the database isn't in a consistent state

also, imagine the first row inserts fine, but then
a valid error correctly prevents the second row from being inserted
there could be a uniqueness conflict on the second row, for instance

using the supabase api, each insert is a separate statement
js code will have to notice the error on the second insert
and then go back and try to remove the first

but this problem was solved in databases decades ago!
with somethign called the transaction
the begin and commit lines above group the two inserts into a single transaction
and, sure enough, if there's a problem anywhere in there, none of it sticks
and all of this is automatic

so you want to be able to use transactions
the problem is, the supabase api doesn't include them
under the hood this may be because the supabase api uses postgrest, and postgrest doesn't support them
there isn't a way to do two inserts in a single call to the supabase api, either
even with all the method chaining









hide, 0 by default, then nonzero to hide the row, perhaps because it's made not relevant by later rows, like the user deleted it, or edited it, or it's no longer necessary to come to the same conclusion
hidden rows should never never be sent to the client, for any reason--it's ok for the server to look at them and make decisions based upon them, though
but even that should be rare--when performing an audit for a staff member, or something related to keeping the system secure as it runs





for now you're storing json in _text
and only in instances where you never need to filter or query on it

another thing we're not doing
labeling any columns UNIQUE in the schema
tags are globally unique
and row_tag column is unique, as the PRIMARY KEY must be unique
but other columns that have tags absolutely have duplicates! multiple rows need to record facts about the same tag, like browser tag or user tag!
unique makes postgres autoatically make an index
but we're adding compound indices designed to match common queries by design
so we don't need more individual indices








supabase trello
[]backup and download
[]restore into local postgres
[]restore into supabase
[]setup automatic backups every hour
[]that go to an amazon bucket



































first, sketch out on paper what the user does and what the system does through valid flows

a user, already signed in, returns to the site

an attacker enters a victims email address many times to get the victim to be sent codes they don't need

a user signes up with email
and then validates that email address

a user, already signed in, 

an anonymous user sets their nickname, and stars something

a signed-in user authenticates with another factor to perform a protected action, like changing sign in
these permissions only extend to their current device
an hour later, their permission level on that device returns to normal

a new user gets codes to validate their email address adn then sms number
the second code they get is code B
the third code they get is 6 digits, not 4

a user signs in on desktop
then on mobile
returns later and is still signed in
then signs out of everywhere on desktop

a signed in user visits a page that shows them
where they are currently signed in
where they have previously been signed in
with information from the browser's reported query string and geolocation, like city and country


















== user identity 0.01

imagine this subset
no anonymous users
no email or sms or anything else
it's a user name, and a password
under the hood, there's a browser tag, and a user tag
users can sign up, sign in, sign out
users can delete their account, even--another user can sign up with that name
users can change their user name, their user tag does not change
two different users can share a computer

and a user has a page,
where there is a counter they can change
and a message they can change
(oh, their page also has a card:)

and if they are signed in, it shows where they are signed in
and where they used to be signed in, also
with just this, you can code the list that shows where the user is signed in,
and where they have been signed in

yeah, that's a good user identity 0.01
and also will show you
and then after that, add email
and by adding email successfully, you enable multifactor within the same schema
and email also includes one time codes
and forgot password, that flow

and after that, add sms
which is like another kind of email
and also has forgot password, validate, one time codes, code expiration, rate limiting
lots of advanced stuff

this is your current idea of how you get started with user identity
(1) password, demonstrating linking browserTag and userTag
(2) email, demonstrating one time code validation and forgot password and more
(3) sms, as an alternative additional method to email that you can add without much additional code or schema






you just realized if you don't do password at all
you don't have to do the forgot password reset password flow


















a user has a page and a message they can set
other users can see this page, but only the user can change it

a user's page has a card, which shows their name and when they signed up

a user's page can also have a list of where they're signed in








you just realized when you're doing the super authentication that only lasts 1 hour, or wahtever, and only exists on one browser, you can do that like this:

user_tag  signed_in
alice     2 <--meaningful
alice     1

assuming that the time now is within an hour of the 2 row










also, let's design assuming two things
-supabase api always works
-two or more supabase commands do complete as a transaction (there isn't the same user writing a similar thing at the same time)
at this point, those assumptions are necessarily, essentially, to be able to move forward






records a user's lifecycle
0 does not actually exist in this table or anywhere else, reserved
1 new anonymous user we're letting leave traces, but who has not signed up yet
2 regular signed up user in good standing
3 account hidden, could be unhidden
4 account closed
notice how permissions (creator, staff) are reflected elsewhere
notice how reason for deleting (banned, user left) are also not reflected here






later realized, an account could also be temporarily suspended by staff
while we clear something up with a user, who, if in chat oob, promises to not do that again
so both closed and hidden can be done by user or staff










super permission hour:

first factor: (fans)
- browser tag
- no expiration

second factor: (creators, or a destructive operation)
- browser tag
- user tag, signed in at that browser
- ip address, according to connection (trustworthy)
- user agent string, according to headers (less trustworthy)
- OpenGL hardware, according to browser (less trustworthy)
- one hour expiration, according to server clock (trustworthy)




when do we create the anonymous user?
we could when we first see a new browser tag; we'll have a lot of them
we could instead when a new person first clicks Follow, or sets their nickname



totally make the service_table
which is a history and audit of every request and every response to every api
so you can see what worked and what didn't work
and how quickly the api responded
and how quickly the user was able to complete the task related to the api
start recording this information even before you have a system that uses it
















the idea of how you approach
start with the schema
the very bottom, upwards
then the functions that access that table
place data in supabase manually
code the read pathways
then after all that is done, do the edit and write pathways

previously you've been thinking write first, smallest possible loop
but those get too big and too complicated when you switch from simple examples to real interactions












user_table
0 unused
1 provisional/epehemeral, tracks information of this person at this browser, who may have added a dob or credit card number or clicked follow. but then not finished. so they can't sign in anywhere else
2 actual/normal/standard/full





ok here's a common case
a new person navigates a browser
enters dob and sms, server sends code
then, they don't validate it, they just don't bother
	at this point, as they have entered information, they have a user tag and level 1 provisional

next day, return to that browser, looks up same user tag, that's all fine

but what if then, they go to their other computer or phone
navigate a browser
click sign up, now, they're interested in finishing the process
enter the same dob and same sms
server should send code
now, they type in the code

so they've properly finished steps to create a new account on the second computer
what happens to the first computer?
is that provisional user discarded?
is it signed in as them?
when, on computer 2, they enter the same dob, we have to give them a user tag
but then, when they enter also the same sms, do we switch to the existing provisional user tag?








hmm, maybe there is a level
0 sign out
1 provisional (clicked Follow or entered a phone number to get a code, didn't do anything more. user can pick up wher they left off by returning to this browser. they can't sign out, though, because they're not really signed in)
2 actual (full account signed in. the user can sign out)
3 dual factored (just for the next hour, and just on this browser, the user has elevated permissions)







slept on it
if it's simpler (but you don't think it is) you could blow away a browser's provisional user if some other user signs in there
provisional useres are great to help new people sign in for the first time
but in a corner case that's more complex than that, it's actually a little weird if you're signing out and then there's still some fragment of something different left behind
the most common cas when this will happen is it's the same human, who signed up and in disjointedly
so yeah, you probably should blow away


























