<script setup>

/*
Uppy CSS: static imports for Dashboard styles. Unlike Vidstack (which has a Vite plugin
that auto-extracts CSS from 'vidstack/bundle'), Uppy requires explicit CSS imports.
Nuxt/Vite will extract these into a code-split CSS chunk loaded only when this component
is used. CSS has no browser globals, so static imports work fine with SSR - only the JS
needs dynamic importing via uppyDynamicImport() to avoid Cloudflare Workers issues.
*/
import '@uppy/core/css/style.min.css'
import '@uppy/dashboard/css/style.min.css'

import {
uppyDynamicImport,
origin23,
passwordHash, Data,
hashFile, hashStream,
browserIsBesideAppStore,
} from 'icarus'

let uppyInstance

const refPassword = ref('')
const refStatus = ref('')//status text shown below password box
const refEnvelope = ref(null)//reactive so template can switch from password box to uppy dashboard

//track state per file: hashes, key, pieceHash promise
const fileState = new Map()//fileId -> {filename, size, tipHash, pieceHashPromise, pieceHash, key, tag}

async function onPasswordEnter() {
	if (!refPassword.value) return
	refStatus.value = 'Hashing...'
	let hash = await passwordHash({
		passwordText: refPassword.value,
		cycles: Number(Key('upload demonstration password cycles, public')),
		saltData: Data({base62: Key('password, salt, public')}),
	})
	refStatus.value = 'Checking...'
	let response = await fetchWorker('/api/media', {body: {action: 'MediaDemonstrationUpload.', hash}})
	if (response.reason == 'BadPassword.') { refStatus.value = 'Wrong password'; return }
	refEnvelope.value = response.envelope
	refStatus.value = 'Unlocked'
	await nextTick()//wait for Vue to render #uppy-dashboard div before mounting Uppy into it
	await mountUppy()
}

async function fetchUpload(body) {
	return await $fetch(`${origin23()}/upload`, {//use Nuxt $fetch rather than browser fetch to throw on non 2XX; fetchLambda is only for worker<->lambda calls, here, we the page are contacting the /upload lambda directly
		method: 'POST',
		body: {...body, envelope: refEnvelope.value},
	})
}

async function mountUppy() {
	const uppy_modules = await uppyDynamicImport()
	uppyInstance = new uppy_modules.uppy_core.default()
	uppyInstance.use(uppy_modules.uppy_dashboard.default, {
		inline: true,
		target: '#uppy-dashboard',
	})
	uppyInstance.use(uppy_modules.uppy_aws_s3.default, {
		shouldUseMultipart: () => true,

		async createMultipartUpload(file) {
			//wait for tipHash + Worker check before starting upload (eliminates race condition)
			let state = fileState.get(file.id)
			if (state?.readyPromise) {
				await state.readyPromise
				//later: Worker could return {skip: true} if tipHash already exists, and we'd abort here
			}

			let response = await fetchUpload({action: 'UploadCreate.', filename: file.name, contentType: file.type})
			log('ðŸŽˆ UploadCreate.', look({file}), look(response))

			//tag's tale 3/5: Lambda generated a unique tag for this file, embedded it in the key, and returned both
			if (state) {
				state.key = response.key//the bucket path the lambda chose for this individual file upload attempt
				state.tag = response.tag//and the tag it picked for it, which is also baked into key, but here separate so we dont' have to do the work of parsing it out
			}

			return {uploadId: response.uploadId, key: response.key}
		},

		async signPart(file, {uploadId, key, partNumber}) {
			let response = await fetchUpload({action: 'UploadSign.', uploadId, key, partNumber})
			log('ðŸŽˆ UploadSign.', look({file, uploadId, key, partNumber}), look(response))
			return {url: response.url}
		},

		async completeMultipartUpload(file, {uploadId, key, parts}) {
			await fetchUpload({action: 'UploadComplete.', uploadId, key, parts})
			log('ðŸŽˆ UploadComplete.', look({file, uploadId, key, parts}))
			return {}
		},

		async abortMultipartUpload(file, {uploadId, key}) {
			await fetchUpload({action: 'UploadAbort.', uploadId, key})
			log('ðŸŽˆ UploadAbort.', look({file, uploadId, key}))
		},

		async listParts(file, {uploadId, key}) {
			let response = await fetchUpload({action: 'UploadList.', uploadId, key})
			log('ðŸŽˆ UploadList.', look({file, uploadId, key}), look(response))
			return response
		},
	})

	//when user adds a file, compute browser-side hashes
	uppyInstance.on('file-added', async (file) => {
		log('ðŸŽˆ file-added', look({id: file.id, name: file.name, size: file.size, type: file.type}))

		let state = {
			filename: file.name,
			size: file.size,
			readyPromise: null,//resolves when tipHash computed and Worker consulted; createMultipartUpload awaits this
			tipHash: null,
			pieceHashPromise: null,
			pieceHash: null,
			key: null,
			tag: null,//tag's tale 1/5: starts null, will be set when Lambda generates it in createMultipartUpload
			//^each single attempt of a single file gets a new tag, generated by a server (not this untrustworthy page!) this tag keeps destinations unique in the bucket, and is important during the lifetime of the upload attempt. if the user in this same session uploads two files, they'll each have unique tags. if they try to upload the same file again, it will be a new attempt, and also get a unique tag. once an upload is done and we've hashed the file, we don't need tag, at the very end we index everything by hash
		}
		fileState.set(file.id, state)

		//[1] compute tipHash and check with Worker before upload can start
		//createMultipartUpload awaits this promise, so upload won't begin until tipHash is ready
		state.readyPromise = (async () => {
			let tipResult = await hashFile({
				file: file.data,
				size: file.size,
			})
			state.tipHash = tipResult.tipHash.base32()
			log('ðŸŽˆ tipHash computed', look({id: file.id, tipHash: state.tipHash, duration: tipResult.duration}))

			//report tipHash to Worker (for short-circuit check, just logging for now)
			let workerResponse = await fetchWorker('/api/media', {body: {
				action: 'UploadHash.',
				tag: state.tag,
				filename: state.filename,
				size: state.size,
				browserTipHash: state.tipHash,
			}})
			return workerResponse//later: could return {skip: true} if file already exists
		})()

		//[2] on desktop, start pieceHash concurrently (don't await, runs in background)
		if (!browserIsBesideAppStore()) {
			state.pieceHashPromise = hashStream({
				stream: file.data.stream(),
				size: file.size,
			}).then(result => {
				state.pieceHash = result.pieceHash.base32()
				log('ðŸŽˆ pieceHash computed', look({id: file.id, pieceHash: state.pieceHash, duration: result.duration}))
				return result
			})
		}
	})

	//when upload completes, verify with Lambda and report to Worker
	uppyInstance.on('upload-success', async (file, response) => {
		log('ðŸŽˆ upload-success', look({id: file.id, name: file.name, response}))

		let state = fileState.get(file.id)
		if (!state) { log('ðŸŽˆ upload-success: no state for file', file.id); return }

		//wait for pieceHash to finish if still running (desktop only)
		if (state.pieceHashPromise) {
			await state.pieceHashPromise
		}

		//report browser hashes to Worker (before Lambda verification)
		await fetchWorker('/api/media', {body: {
			action: 'UploadHash.',
			tag: state.tag,
			filename: state.filename,
			size: state.size,
			browserTipHash: state.tipHash,
			browserPieceHash: state.pieceHash,//null on mobile
		}})

		//[3] ask Lambda to hash the uploaded file
		let lambdaResult = await fetchUpload({
			action: 'UploadHash.',
			tag: state.tag,
			key: state.key,
			filename: state.filename,
		})
		log('ðŸŽˆ Lambda UploadHash.', look({id: file.id, lambdaResult}))

		//report everything to Worker including Lambda's attestation
		await fetchWorker('/api/media', {body: {
			action: 'UploadHash.',
			tag: state.tag,
			filename: state.filename,
			size: state.size,
			browserTipHash: state.tipHash,
			browserPieceHash: state.pieceHash,
			bucketEnvelope: lambdaResult.bucketEnvelope,
		}})

		//compare hashes (happy path logging for now)
		let tipMatch = state.tipHash === lambdaResult.tipHash
		let pieceMatch = state.pieceHash === lambdaResult.pieceHash || !state.pieceHash//mobile has no pieceHash
		log('ðŸŽˆ verification', look({
			id: file.id,
			tipMatch,
			pieceMatch,
			browserTip: state.tipHash,
			lambdaTip: lambdaResult.tipHash,
			browserPiece: state.pieceHash,
			lambdaPiece: lambdaResult.pieceHash,
		}))

		if (tipMatch && pieceMatch) {
			log('âœ… Verified!', file.name)
		} else {
			log('âŒ Hash mismatch!', file.name)
		}
	})
}

onUnmounted(() => {
	if (uppyInstance) {
		uppyInstance.destroy()
		uppyInstance = null
	}
})

/*
Why vanilla JS instead of @uppy/vue:

@uppy/vue provides thin Vue wrappers like <Dashboard :uppy="uppy" /> that handle mounting/unmounting
for you. However, these components expect a pre-existing Uppy instance passed as a prop, which
conflicts with our dynamic import pattern - we can't create the instance until after the async
import resolves. We'd need something like:

  const uppy = shallowRef(null)
  onMounted(async () => { uppy.value = new (await uppyDynamicImport()).uppy_core.default() })
  <Dashboard v-if="uppy" :uppy="uppy" />

This adds complexity (shallowRef, v-if guard, prop drilling) for little benefit. The vanilla JS
approach is simpler: mount to a DOM target in onMounted, destroy in onUnmounted. We handle the
same lifecycle @uppy/vue would handle, but with full control and no extra abstraction layer.

Trade-off: @uppy/vue would give us reactive props (e.g., dynamically changing `plugins` or `theme`).
We don't need that here - our config is static. If we later need reactive Uppy config, we could
revisit, but for static Dashboard usage, vanilla JS is cleaner
*/

</script>
<template>
<div class="border border-gray-300 p-2">
<p class="text-xs text-gray-500 mb-2 text-right m-0 leading-none"><i>UppyDemo</i></p>
<div v-if="!refEnvelope" class="mb-2">
	<PasswordBox v-model="refPassword" @enter="onPasswordEnter" placeholder="Upload password..." class="w-72" />
	<span v-if="refStatus" class="ml-2">{{ refStatus }}</span>
</div>
<div v-if="refEnvelope" id="uppy-dashboard"></div>
</div>
</template>
